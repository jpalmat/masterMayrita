{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b029b32-4a9d-4dd9-97e2-cc26bdf7e9d6",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "<img src=\"img/viu_logo.png\" width=\"200\">\n",
    "<br><br>\n",
    "    \n",
    "<div style=\"text-align: center;\">\n",
    "    \n",
    "<h1>UNIVERSIDAD INTERNACIONAL DE VALENCIA</h1>\n",
    "<h2>MASTER EN INTELIGENCIA ARTIFICIAL</h2><br>\n",
    "__________________________________________________________________________________________________________________\n",
    "<h3>MEMORIA DEL CURSO MATEMÁTICAS PARA LA INTELIGENCIA ARTIFICIAL</h3>\n",
    "<h3 style=\"text-align: center;\">PROGRAMACIÓN LÓGICA INDUCTIVA: METÓDOS Y TEORÍAS</h3>\n",
    "__________________________________________________________________________________________________________________\n",
    "<br><br>\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<h4>ALUMNOS: </h4>\n",
    "<h5>Franklin Garcia Ruiz</h5>\n",
    "<h5>Cristian Francisco Rojas Ledezma</h5>\n",
    "<h5>Laura Rodriguez King</h5>\n",
    "<h5>Mayra Pullupaxi Ataballo</h5>\n",
    "<br><br>\n",
    "\n",
    "</div>\n",
    "</div>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd06d6a5-a3a6-423b-88da-73c9b5b2b501",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align: center; margin: 0 0 2em 0\">BY STEPHEN MUGGLETON AND LUC DE RAEDT</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6440945d-6a16-456e-add7-cd39c65c9421",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify;\">\n",
    "    \n",
    "<p>La memoria de este artículo científico gira en torno a la programación lógica inductiva, y por ende su contenido detalla sobre su proceso, metodología, aplicaciones e interacciones, pero ¿qué es la ILP o programación lógica inductiva? Para dar respuesta a esta primera y central inquietud hagamos uso del método deductivo e iniciemos por entender su entorno de trabajo.</p>\n",
    "\n",
    "<p>Globalizadamente la ILP se describe en cuatro niveles: nivel semántico, nivel algorítmico, nivel demostrativo-teórico y nivel semántico probabilístico de confianza.</p>\n",
    "\n",
    "<p>En ese orden de ideas la Programación lógica inductiva primero detecta y define el problema, seguido a ello, define y estudia que reglas de la inferencia aplican a dicho problema, los algoritmos de ILP transforman esas reglas para que sean comprendidas con facilidad (computacionalmente costoso para ser de interés práctico) y finaliza con la justificación de las hipótesis de inducidad.</p>\n",
    "\n",
    "<p>Ahora bien, los niveles hablan del término \"semántica\" y de hecho es un término bastante común en la ILP que debemos comprender para abarcar el estudio de la programación lógica inductiva.</p>\n",
    "\n",
    "<p>La semántica definida como elementos lógicos, hacen parte del modelo-teórico del ILP y podemos encontrar dos tipos: la semántica normal y no monotónica.</p>\n",
    "\n",
    "<h4>Iniciemos con la semántica normal:</h4>\n",
    "\n",
    "<p>Dentro del modelo-teórico el objetivo de la semántica normal es hallar una hipótesis tal que cumpla con la siguiente condición:</p>\n",
    "\n",
    "<img src=\"img/img4.png\">\n",
    "\n",
    "<p>Donde B equivale al conocimiento previo, E como la evidencia y por último H como la hipótesis, cabe resaltar que la evidencia puede ser positiva (verdadera) o negativa (falsa).</p>\n",
    "\n",
    "<p>El criterio de suficiencia en ocasiones actúa como la integridad con respecto a la evidencia positiva y el criterio de satisfabilidad posterior como consistencia con evidencia negativa.</p>\n",
    "\n",
    "<p>La semántica normal posee un caso especial llamado \"semántica definida\" y su configuración es más sencilla puesto que trabaja con el modelo Herbrand y la evidencia se restringe a ser verdadera o falsa.</p>\n",
    "\n",
    "<img src=\"img/img2.png\">\n",
    "\n",
    "<h4>Semántica No-monotónica:</h4>\n",
    "\n",
    "<p>Introducido por Nicolas Helf y Flach, este escenario se compone de un grupo de cláusulas definidas (teoría de fondo), evidencia vacía e hipótesis usando el mismo alfabeto que la teoría de fondo.</p>\n",
    "\n",
    "<p>Para este entorno, se deben cumplir las siguientes condiciones para H y B:</p>\n",
    "\n",
    "<img src=\"img/img3.png\">\n",
    "\n",
    "<p>La principal disimilitud entre ambos escenarios radica en que el entorno normal la hipótesis inducida puede ser utilizada como reemplazo ya que tanto la teoría como la hipótesis implican ejemplos observados, mientras que en el escenario no monotónico, la hipótesis es un conjunto de propiedades que contiene un conjunto de ejemplos.</p>\n",
    "\n",
    "<img src=\"img/img1.png\">\n",
    "\n",
    "<p>Y aunque ambas parezcan muy diferentes, ambas aplican técnicas del ILP en común.</p>\n",
    "\n",
    "<p>Para la formación y justificación de hipótesis  basta con entender la siguiente fórmula:</p>\n",
    "\n",
    "<p>Induction = Abduction + Justification</p>\n",
    "\n",
    "<p>Detalladamente así:</p>\n",
    "\n",
    "<p>Induction = Formación de hipótesis + Grado de creencia de la hipótesis reforzada con la cantidad de evidencias.</p>\n",
    "\n",
    "<p>El sesgo es la influencia que tienen las inferencias inductivas con base a la experiencia, y se distinguen el sesgo declarativo que lanza la pregunta ¿Qué buscar? y el sesgo preferencial que determina ¿Cómo buscar? y con esto damos entrada a las probabilidades semánticas de la ILP.</p>\n",
    "\n",
    "<h4>Expón la interacción entre esta disciplina y la probabilidad, así como el rol que juega el teorema de Bayes y, en general, la inferencia bayesiana.</h4>\n",
    "\n",
    "\n",
    "<p>La interacción entre ambas disciplinas yace en que son aplicables incluso en la escasa posibilidad de tener solo ejemplos positivos disponibles. Cada consigna lógica inferida inductivamente tiene un valor de probabilidad. El rol que juega el teorema Bayesiano dentro del entorno ILP es la confirmación y corroboración de hipótesis, por ejemplo:</p>\n",
    "\n",
    "<p>Supongamos que estamos intentando demostrar un grado de creencia y nos llega un ejemplo con negativos, es aquí donde debemos devolvernos a la sesión anteriormente explorada de la satisfactibilidad posterior que se encargará de reemplazar el elemento superior único por un conjunto de elementos superiores, y con ello hacer uso del teorema de Bayes:</p>\n",
    "\n",
    "<img src=\"img/img5.png\">\n",
    "\n",
    "<p>Resta asumir que la evidencia es correcta, esto conduce a la paradoja de si T tiene un conjunto finito de modelos es necesariamente falso y se aplica la inferencia bayesiana en la toma de decisión e inferir que la hipótesis es cierta.</p>\n",
    "\n",
    "<p>Entonces la inferencia Bayesiana toma sentido cuando hay gran cantidad de circunstancias en donde debido a las posibilidades de controlar errores se puede aplicar enfoques de probabilidad inductivos en donde la probabilidad puede ser actualizada de acuerdo a las hipótesis planteadas y evidencias encontradas.</p>\n",
    "\n",
    "<p>De la probabilidad pasamos a la estadística con sus técnicas de regresión en las redes neuronales. Ya anteriormente habíamos visto que los algoritmos generan reglas fáciles de comprender a diferencia de estos imitadores del aprendizaje humano. Durante años se han realizado diversos intentos para solventar los problemas de predicción general, El instituto de Turing recientemente logró un notable acercamiento a la predicción general haciendo uso de conocimientos biológicos previos y la capacidad de describir relaciones estructurales.</p>\n",
    "    \n",
    "<p>Para la conexión entre el aprendizaje automático y las redes reuronales se necesita proporcionar la suficiente cantidad de datos a las capas de las neuronas para que puedan reconocer patrones, clasificarlos y categorizarlos, para ello usa algoritmos para procesar datos, aprender de ellos y ser capaces de hacer predicciones, al trabajar con gran cantidad de datos permite que los algoritmos sean mejorados y obtiene mejores resultados.</p>\n",
    "\n",
    "<p>A diferencia de la inferencia deductiva que trabaja a partir de fórmulas lógicas suministradas por el usuario y a partir de conocimientos previos logrando una predicción por hechos ya registrados y en las probabilidades la inferencia inductiva no garantiza que las conclusiones sigan mas allá de lo que se sabe y por ende el razonamiento inductivo sigue siendo menos conciso que las matemáticas deductivas.</p>\n",
    "\n",
    "<p>Pongamos un par de ejemplos para hacer más clara la precisión de ambos conceptos:</p>\n",
    "\n",
    "<h4>Lógica inductiva:</h4>\n",
    "\n",
    "<p>Las manos de un humano generalmente tiene 5 dedos, lo que se podrían inducir que las manos tienen 5 dedos, sin embargo, en algún lugar del mundo podría nacer un humano con 6 dedos, o incluso sin dedos, a esto le llamamos lógica inductiva, donde la hipótesis puede ser revocada por evidencias.</p>\n",
    "\n",
    "<h4>Lógica deductiva:</h4>\n",
    "\n",
    "<p>Los animales herbívoros comen plantas, la vaca come planta, por lo tanto la vaca es herbívora.</p>\n",
    "\n",
    "<p>Y para finalizar la lógica inductiva tiene una orientación semántica y varias técnicas bien establecidas, además de que está interesada en la convergencia de algoritmos, complejidad de los procesos, potencialmente utilizada para el análisis, aplicación de teorías incluso creación de las mismas. Casos de éxito como en la medicina muestra que la ILP es capaz de construir nuevas reglas que predicen la actividad de las medicinas aún no testeadas en humanos y permite encontrar mayor precisión que otros métodos. Así, pasando de lo general a lo particular, cerramos la memoria ILP como el proceso que emplea técnicas de aprendizaje automático encargado de expandirnos el horizonte. \n",
    "</p>\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
