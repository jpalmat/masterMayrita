{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GANs - 3. Mi primera DCGAN en color - CIFAR10.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMQrhcijCTM1gs7JS5dwTkS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"_j-qgSlJFC0u"},"source":["**PRÁCTICA**: Buscad las diferencias con la DC GAN en escala de grises. En 10 minutos las ponemos en común y ejecutamos paso a paso para ver los resultados."]},{"cell_type":"code","metadata":{"id":"HOkhqpcqGFq8"},"source":["# importamos las librerías necesarias\n","import numpy as np\n","from tensorflow.keras.datasets.cifar10 import load_data\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU, Dropout\n","# configuramos Colab para que nos muestre las imágenes más grandes\n","import matplotlib.pyplot as plt\n","plt.rcParams[\"figure.figsize\"] = (10,10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vZwSsm89GTgc"},"source":["# definimos el discriminador\n","def define_discriminator(in_shape=(32,32,3)):\n","\tmodel = Sequential()\n","\t# normal\n","\tmodel.add(Conv2D(64, (3,3), padding='same', input_shape=in_shape))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# downsample (por el atributo 'strides')\n","\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# downsample\n","\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# downsample\n","\tmodel.add(Conv2D(256, (3,3), strides=(2,2), padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# clasificador\n","\tmodel.add(Flatten())\n","\tmodel.add(Dropout(0.4))\n","\tmodel.add(Dense(1, activation='sigmoid'))\n","\t# compilamos modelo\n","\topt = Adam(lr=0.0002, beta_1=0.5)\n","\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","\treturn model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k-x8dUj2GV02"},"source":["# definimos el generador\n","def define_generator(latent_dim):\n","\tmodel = Sequential()\n","\tn_nodes = 256 * 4 * 4\n","\tmodel.add(Dense(n_nodes, input_dim=latent_dim))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\tmodel.add(Reshape((4, 4, 256)))\n","\t# upsample a 8x8\n","\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# upsample a 16x16\n","\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# upsample a 32x32\n","\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# salida (nuestra imagen fake)\n","\tmodel.add(Conv2D(3, (3,3), activation='tanh', padding='same'))\n","\treturn model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LLqkfLZhGXla"},"source":["# definimos el modelo GAN combinando generador y discriminador, para entrenar el generador\n","def define_gan(g_model, d_model):\n","    # Así que congelamos el discriminador:\n","    d_model.trainable = False\n","    # ahora conectamos el G(z) al D(x)\n","    model = Sequential()\n","    # añadimos el generador primero: él es el encargado de generar una muestra\n","    # a partir del espacio latente\n","    model.add(g_model)\n","    # y el discriminador después: le introducimos la muestra generada por el \n","    # G(z) para que nos diga si cree que es real o fake\n","    model.add(d_model)\n","    # y ahora sí, compilamos el modelo\n","    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5)) \n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aA9vbUANG7uh"},"source":["# definimos las funciones para cargar el MNIST\n","def load_real_samples():\n","    # cargamos el cifar10\n","    (trainX, _), (_, _) = load_data()\n","    # convertimos a float32\n","    X = trainX.astype('float32')\n","    # escalamos entre -1 y 1\n","    X = (X - 127.5) / 127.5\n","    return X\n","\n","# nos creamos una función que nos devuelva n_samples del dataset con sus \n","# etiquetas (1) \n","def generate_real_samples(dataset, n_samples):\n","    # seleccionamos n_samples muestras aleatoriamente\n","    ix = np.random.randint(0, dataset.shape[0], n_samples)\n","    # las cogemos\n","    X = dataset[ix]\n","    # generamos las etiquetas reales (1)\n","    y = np.ones((n_samples, 1))\n","    return X, y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fE_OxdaAHJTS"},"source":["# generamos los vectores latentes que introduciremos al generador\n","def generate_latent_points(latent_dim, batch_size):\n","    # generamos un vector de batch_size * latent_dim números aleatorios\n","    # latent_dim es la dimensión del vector latente\n","    # batch_size es el número de elementos por batch\n","    x_input = np.random.randn(latent_dim * batch_size)\n","    # redimensionamos el vector para que tenga un tamaño (batch_size, latent_dim)\n","    x_input = x_input.reshape(batch_size, latent_dim)\n","    return x_input\n","\n","# creamos datos fake con el generador (dinero falsificado)\n","def generate_fake_samples(g_model, latent_dim, n_samples): \n","    # usamos la función anterior para generar los vectores latentes que \n","    # necesitamos para generar muestras fake\n","    x_input = generate_latent_points(latent_dim, n_samples)\n","    # le introducimos los vectores latentes al generador para obtener\n","    # muestras similares a las reales\n","    X = g_model.predict(x_input)\n","    # le asignamos la etiqueta 0 (porque utilizaremos esta función para\n","    # entrenar el D)\n","    y = np.zeros((n_samples, 1)) \n","    return X, y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4lwyWzu3HVc3"},"source":["# función para guardar las imágenes generadas\n","def save_plot(examples, epoch, n=7):\n","\t# escalamos de [-1,1] (la salida de nuestra gan, debido a la función de activación tanh) a [0,1]\n","\texamples = (examples + 1) / 2.0\n","\tfor i in range(n * n):\n","\t\tplt.subplot(n, n, 1 + i)\n","\t\tplt.axis('off')\n","\t\tplt.imshow(examples[i])\n","\t# guardamos las imágenes\n","\tfilename = 'generated_plot_e%03d.png' % (epoch+1)\n","\tplt.savefig(filename)\n","\tplt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wF-VEBxYHxvT"},"source":["# función para entrenar la GAN: el discriminador y el generador\n","def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=128):\n","    bat_per_epo = int(dataset.shape[0] / n_batch)\n","    half_batch = int(n_batch / 2)\n","    # bucle para las epochs\n","    for epoch in range(n_epochs):\n","        # bucle para los batch\n","        for batch in range(bat_per_epo):\n","            \n","            # en esta ocasión vamos a separar las pérdidas del discriminador\n","            # cuando le metemos imágenes reales y cuando le metemos imágenes\n","            # fake para ver cómo lo hace con cada tipo\n","            # recordad que lo ideal es que llegue a un 50% de acc en cada uno\n","\n","            # preparamos los datos reales\n","            X_real, y_real = generate_real_samples(dataset, half_batch)\n","            # actualizamos el discriminador\n","            d_loss1, _ = d_model.train_on_batch(X_real, y_real)\n","            \n","            # generamos datos falsos\n","            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n","            # actualizamos el discriminador\n","            d_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n","\t\t\t\n","            # preparamos los puntos en el espacio latente: serán la entrada al\n","            # modelo GAN con el que entrenaremos el generador\n","            X_gan = generate_latent_points(latent_dim, n_batch)\n","            \n","            # creamos etiquetas invertidas para el generador: utilizamos el D(x) \n","            # para que piense que las muestras que le introducimos son reales, y\n","            # en caso de que diga que no son reales, aprovechamos la información\n","            # de sus gradientes para actualizar el G(z) para que la próxima vez\n","            # los datos generados por G(z) sean más plausibles (parecidos a los \n","            # reales)\n","            y_gan = np.ones((n_batch, 1))\n","            \n","            # como acabamos de ver, entrenamos el generador de forma que actualice\n","            # sus pesos usando los gradientes del discriminador\n","            # tened en cuenta que en este modelo (gan_model) el discriminador está\n","            # congelado, por lo que no se actualizan sus pesos: no queremos \"untar\"\n","            # a nuestro policía, lo que queremos es fabricar dinero más realista.\n","            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n","            \n","            # mostramos el progreso\n","            print('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' % \n","                  (epoch+1, batch+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n","        # evaluate the model performance, sometimes\n","        if (epoch+1) % 10 == 0 or epoch == 0:\n","            # preparamos ejemplos reales\n","            X_real, y_real = generate_real_samples(dataset, n_batch)\n","            # evaluamos el discriminador con datos reales\n","            _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n","            # preparamos ejemplos fake\n","            x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_batch)\n","            # evaluamos el discriminador con datos fake\n","            _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n","            # mostramos cómo de bueno es nuestro policía\n","            print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n","            # guardamos las imágenes generadas\n","            save_plot(x_fake, epoch)\n","            # guardamos el generador para tenerlo disponible más tarde\n","            filename = 'generator_model_%03d.h5' % (epoch + 1)\n","            g_model.save(filename)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tr-_KR-3vvXX"},"source":["# size of the latent space\n","latent_dim = 100\n","# create the discriminator\n","d_model = define_discriminator()\n","# create the generator\n","g_model = define_generator(latent_dim)\n","# create the gan\n","gan_model = define_gan(g_model, d_model)\n","# load image data\n","dataset = load_real_samples()\n","# train model\n","train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=20, n_batch=256)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L6WVl-OtxuCs"},"source":["# veamos los archivos generados\n","ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4dOo6GMgydkw"},"source":["# montamos la unidad drive donde tenemos los datos en la carpeta drive/My Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uvmFAnEoyHky"},"source":["# los guardamos en nuestro drive para evitar tener que reejecutar cada vez\n","!mkdir drive/My\\ Drive/5_dcgan_color_cifar10\n","!cp *gen* drive/My\\ Drive/5_dcgan_color_cifar10/\n","!ls -lah drive/My\\ Drive/5_dcgan_color_cifar10/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f4R0-4oObqdd"},"source":["plt.imshow(plt.imread('generated_plot_e001.png'))\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Px6TeEEKhkOR"},"source":["plt.imshow(plt.imread('generated_plot_e020.png'))\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YAY44jflhrjX"},"source":["# no se ve bien, vamos a generar imagenes con el generador guardado!"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ah-muUXwkGCC"},"source":["def plot_results(imgs, n_rows, n_cols, epoch, h=32, w=32):\n","    imgs = (imgs + 1) / 2.0\n","    output_img = np.zeros((n_rows*h, n_cols*w, 3), np.float)\n","    k = 0\n","    for i in range(n_rows):\n","        for j in range(n_cols):\n","            output_img[h*i:h*(i+1), w*j:w*(j+1), :] = imgs[k]\n","            k += 1\n","    plt.imshow(np.asarray(output_img*255., np.uint8))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BgFbOq0ntX1y"},"source":["import numpy as np\n","latent_dim = 100\n","n_samples = 64\n","\n","# definimos el mismo código latente para todos los tests\n","x_input = generate_latent_points(latent_dim, n_samples)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6muosatyjhsj"},"source":["g_model = define_generator(latent_dim)\n","g_model.load_weights('generator_model_001.h5')\n","X = g_model.predict(x_input)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-mDKqsU0kENy"},"source":["X.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iKHp4yuQlAFa"},"source":["plot_results(X, 8, 8, 10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7noecHKsluGw"},"source":["# veamos el modelo 20\n","g_model = define_generator(latent_dim)\n","g_model.load_weights('generator_model_020.h5')\n","X = g_model.predict(x_input)\n","plot_results(X, 8, 8, 100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZZmCvvo-xrse"},"source":["# generamos imágenes diferentes con un código latente distinto\n","x_input = generate_latent_points(latent_dim, n_samples)\n","\n","g_model = define_generator(latent_dim)\n","g_model.load_weights('generator_model_020.h5')\n","X = g_model.predict(x_input)\n","plot_results(X, 8, 8, 200)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9S7pFMti0Oiv"},"source":["# generamos imágenes diferentes con un código latente distinto\n","x_input = generate_latent_points(latent_dim, n_samples)\n","\n","g_model = define_generator(latent_dim)\n","g_model.load_weights('generator_model_020.h5')\n","X = g_model.predict(x_input)\n","plot_results(X, 8, 8, 200)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lzzxVYSr0Qtd"},"source":["# generamos imágenes diferentes con un código latente distinto\n","x_input = generate_latent_points(latent_dim, n_samples)\n","\n","g_model = define_generator(latent_dim)\n","g_model.load_weights('generator_model_020.h5')\n","X = g_model.predict(x_input)\n","plot_results(X, 8, 8, 200)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pv7egRce0WnP"},"source":[""],"execution_count":null,"outputs":[]}]}