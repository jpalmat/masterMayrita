{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izGKkMpohhTa"
   },
   "source": [
    "<center><h1>VC10: Algoritmo APRIORI</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAsz003KMbmS"
   },
   "source": [
    "# RECUERDA RELLENAR TUS DATOS A CONTINUACIÓN ANTES DE HACER NADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2xBNEFw1HJxS"
   },
   "outputs": [],
   "source": [
    "# ===============================================================#\n",
    "# Rellena AQUÍ tu nombre y apellidos antes de hacer nada\n",
    "# ===============================================================#\n",
    "\n",
    "NOMBRE = 'Mayra'\n",
    "APELLIDOS = 'Pullupaxi'\n",
    "\n",
    "# ===============================================================#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0INCuBFvzKe"
   },
   "source": [
    "El algoritmo Apriori es un procedimiento para encontrar subsets frecuentes de ítems. En el caso de la cesta de la compra serían conjuntos de productos que suelen comprarse simultáneamente. \n",
    "\n",
    "\n",
    "Se podría decir que el algoritmo Apriori es una búsqueda en anchura donde, en primer lugar, se buscan todos los subconjuntos $X$ de tamaño 1 que tienen un mínimo soporte sobre el conjunto de transacciones $S$, $soporte(X;S)\\geq minS$, donde el soporte es una métrica que se define como:\n",
    "$$soporte(X;S)=\\frac{|\\{T\\in S:X\\subseteq T\\}}{|S|}$$\n",
    "\n",
    "Así, la primera tarea consiste en detectar todos los subconjuntos de tamaño $1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CB98Wk7NvzKg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generarC1(S):\n",
    "    C1 = []\n",
    "    for transaccion in S:\n",
    "        for item in transaccion:\n",
    "            if [item] not in C1:\n",
    "                C1.append([item])\n",
    "                \n",
    "    C1.sort()\n",
    "    return list(map(frozenset, C1)) # usando un `frozenset´ podemos usarlo como una `key´ de un diccionario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vxmjbv38vzKj"
   },
   "source": [
    "\n",
    "Hagamos una prueba con este pequeño conjunto de transacciones:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YylWJbbJvzKj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[frozenset({1}), frozenset({2}), frozenset({3}), frozenset({4}), frozenset({5})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-02c3d282ced9>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  transacciones = np.array([[2, 3, 4],\n"
     ]
    }
   ],
   "source": [
    "transacciones = np.array([[2, 3, 4], \n",
    "                          [1, 2, 5], \n",
    "                          [1, 2, 3, 5], \n",
    "                          [1, 5]])\n",
    "\n",
    "print(generarC1(transacciones))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEQRCsjpvzKl"
   },
   "source": [
    "Todos los conjuntos de tamaño 1 que superan el umbral $minS$ se combinan para crear conjuntos de tamaño $2$, los cuales también son testeados en busca de aquellos que superan también este umbral, $minS$.\n",
    "\n",
    "En general, todos aquellos conjuntos de la $i$-ésima iteración que superan el umbral de soporte $minS$ (conjuntos de tamaño $|X|=i$), en la siguiente iteración ($i+1$) del algoritmo, se combinan entre ellos para generar nuevos conjuntos de tamaño $i+1$. \n",
    "\n",
    "La siguiente función se usa para identificar los conjuntos que superan el umbral de soporte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "96TcRdhpvzKm"
   },
   "outputs": [],
   "source": [
    "def filtraPorSoporte(S, Ck, minS):\n",
    "    conteo = {}\n",
    "    for tr in S:\n",
    "        for itemset in Ck:\n",
    "            if itemset.issubset(tr):\n",
    "                if itemset not in conteo: \n",
    "                    conteo[itemset] = 1\n",
    "                else: \n",
    "                    conteo[itemset] += 1\n",
    "    numItems = float(len(S))\n",
    "    Ck_minS = []\n",
    "    soporteCk = {}\n",
    "    for itemset in conteo:\n",
    "        \n",
    "        ## P1\n",
    "        soporte = conteo[itemset]/numItems ## P1. Tu código aquí ##\n",
    "        \n",
    "        if soporte >= minS:\n",
    "            Ck_minS.insert(0, itemset)\n",
    "        soporteCk[itemset] = soporte\n",
    "    return Ck_minS, soporteCk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-U9I_53VvzKo"
   },
   "source": [
    "\n",
    "Podemos hacer el cálculo para obtener los conjuntos de tamaño 1 que ocurren en al menos el $50\\%$ de las transacciones del conjunto de entrenamiento:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "wvwS8oWdvzKo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{2, 3, 4}, {1, 2, 5}, {1, 2, 3, 5}, {1, 5}]\n",
      "[frozenset({5}), frozenset({1}), frozenset({3}), frozenset({2})]\n"
     ]
    }
   ],
   "source": [
    "S = list(map(set,transacciones))\n",
    "C1 = generarC1(transacciones)\n",
    "print(S)\n",
    "\n",
    "L1, soporteC1 = filtraPorSoporte(S,C1,0.5)\n",
    "print(L1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a68q0CzdvzKq"
   },
   "source": [
    "\n",
    "Se puede ver que el ítem 4 sólo aparece en la primera transacción, por lo que no superó el umbral de soporte fijado.\n",
    "\n",
    "Probablemente la parte más sensible de este algoritmo consiste en generar los candidados (conjuntos de ítems) de una nueva iteración ($C_k$) dados los conjuntos frecuentes de la previa ($L_{k-1}$). \n",
    "\n",
    "Por ejemplo, dados los conjuntos frecuentes de la primera etapa $\\{1\\}$, $\\{2\\}$, $\\{3\\}$ y $\\{5\\}$, los candidados de tamaño 2 ($C_2$) serán:\n",
    "$\\{1,2\\}$, $\\{1,3\\}$, $\\{1,5\\}$, $\\{2,3\\}$, $\\{2,5\\}$ y $\\{3,5\\}$.\n",
    "\n",
    "En concreto, se podría hacer de la siguiente manera:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "TOYiUF_DvzKq"
   },
   "outputs": [],
   "source": [
    "def generarCk(Lk1, k):\n",
    "    Ck = []\n",
    "    lenLk1 = len(Lk1)\n",
    "    for i in range(lenLk1):\n",
    "        for j in range(i+1, lenLk1): \n",
    "            L1 = list(Lk1[i])[:k-2]\n",
    "            L1.sort()\n",
    "            L2 = list(Lk1[j])[:k-2]\n",
    "            L2.sort()\n",
    "            if L1 == L2: # Si los primeros k-2 elementos son los mismos\n",
    "                Ck.append(Lk1[i] | Lk1[j]) # hacemos la union de ambos conjuntos\n",
    "    return Ck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0IQfS-CvzKs"
   },
   "source": [
    "\n",
    "Se puede comprobar que el resultado cuadra con lo esperado:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "5A_6ab-KvzKs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjuntos candidatos de tamaño 2,\n",
      "C2 = [frozenset({1, 5}), frozenset({3, 5}), frozenset({2, 5}), frozenset({1, 3}), frozenset({1, 2}), frozenset({2, 3})]\n"
     ]
    }
   ],
   "source": [
    "print('Conjuntos candidatos de tamaño 2,\\nC2 =', generarCk(L1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "921Wm21xvzKu"
   },
   "source": [
    "\n",
    "Por último, sólo faltaría definir la función principal del algoritmo que itera entre la formación de conjuntos candidatos y el filtrado de aquellos que cumplen los requisitos de soporte mínimo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "zWNoGIIAvzKu"
   },
   "outputs": [],
   "source": [
    "def apriori(transacciones, minS = 0.5):\n",
    "    S = list(map(set, transacciones))\n",
    "    C1 = generarC1(transacciones)\n",
    "    L1, soporteItemSets = filtraPorSoporte(S, C1, minS)\n",
    "    L = [L1]\n",
    "    k = 2\n",
    "    while (len(L[k-2]) > 0):\n",
    "        Ck = generarCk(L[k-2], k)\n",
    "        Lk, soporteCk = filtraPorSoporte(S, Ck, minS)\n",
    "        soporteItemSets.update(soporteCk)\n",
    "        L.append(Lk)\n",
    "        k += 1\n",
    "    return L, soporteItemSets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWxghkihvzKw"
   },
   "source": [
    "\n",
    "Podemos finalmente buscar todos los conjuntos frecuentes (en este caso, soporte mínimo de $50\\%$) de $S$ haciendo la siguiente llamada;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "USouONszvzKx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjuntos frecuentes de tamaño 1: [frozenset({5}), frozenset({1}), frozenset({3}), frozenset({2})]\n",
      "Conjuntos frecuentes de tamaño 2: [frozenset({1, 2}), frozenset({2, 5}), frozenset({1, 5}), frozenset({2, 3})]\n",
      "Conjuntos frecuentes de tamaño 3: [frozenset({1, 2, 5})]\n",
      "Conjuntos frecuentes de tamaño 4: []\n"
     ]
    }
   ],
   "source": [
    "L, soporteCk = apriori(transacciones)\n",
    "\n",
    "print('Conjuntos frecuentes de tamaño 1:',L[0])\n",
    "print('Conjuntos frecuentes de tamaño 2:',L[1])\n",
    "print('Conjuntos frecuentes de tamaño 3:',L[2])\n",
    "print('Conjuntos frecuentes de tamaño 4:',L[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VraHo1HvzKy"
   },
   "source": [
    "\n",
    "<hr /> \n",
    "\n",
    "<center><h1>Obtener reglas de asociación a partir de conjuntos frecuentes</h1></center>\n",
    "\n",
    "En teoría hemos visto cómo encontrar una serie de conjuntos frecuentes de ítems. Dado un conjunto frecuente, se puede generar una regla de asociación de la siguiente manera.\n",
    "\n",
    "Se trata de recorrer todo el listado de conjuntos frecuentes y estudiar la conveniencia de nuevas reglas dado un valor mínimo de confianza:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "lAhxdFMGvzKy"
   },
   "outputs": [],
   "source": [
    "def generarReglas(L, soporteItemSets, minC=0.7):\n",
    "    lReglas = []\n",
    "    # para crear reglas, sólo podemos considerar conjuntos de tamaño 2 o mayor\n",
    "    if (len(L) == 1):\n",
    "        return lReglas\n",
    "    for i in range(1, len(L)): \n",
    "        for itemset in L[i]:\n",
    "            H1 = [frozenset([item]) for item in itemset]\n",
    "            nuevasReglas = reglasConfianzaMinima(itemset, H1, soporteItemSets, minC)\n",
    "            if (len(nuevasReglas) > 0):\n",
    "                lReglas = lReglas+nuevasReglas\n",
    "    return lReglas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pU43SeRovzK0"
   },
   "source": [
    "\n",
    "Dado un conjunto frecuente $A$ de ítems específico (de tamaño $>2$), recorreremos todos los elementos $e\\in A$ y consideraremos la conveniencia de cada regla $A\\backslash e \\to e$, para lo que calcularemos el valor de confianza de la siguiente manera:\n",
    "\n",
    "$$confianza(A\\backslash e \\to e;S)=\\frac{soporte(A;S)}{soporte(A\\backslash e;S)}$$\n",
    "\n",
    "Así, la función puede definirse como:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "pIE-EQ9MvzK0"
   },
   "outputs": [],
   "source": [
    "def reglasConfianzaMinima(itemset, H, soporteItemSets, minC=0.7):\n",
    "    lReglas = []\n",
    "    for consecuente in H:\n",
    "        # Calcular confianza\n",
    "        itemsetSINcons = itemset-consecuente\n",
    "        \n",
    "        # P2\n",
    "        conf = soporteItemSets[itemset]/soporteItemSets[itemsetSINcons] ## P2. Tu código aquí ##\n",
    "        \n",
    "        if conf >= minC: \n",
    "            print(itemset-consecuente,'-->',consecuente,'con confianza:',conf)\n",
    "            lReglas.append((itemset-consecuente, consecuente, conf))\n",
    "    return lReglas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0qQtS0yvzK2"
   },
   "source": [
    "\n",
    "Finalmente, podemos buscar las reglas que tengan un mínimo de confianza del $70\\%$:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "gKowdQXkvzK2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({5}) --> frozenset({1}) con confianza: 1.0\n",
      "frozenset({1}) --> frozenset({5}) con confianza: 1.0\n",
      "frozenset({3}) --> frozenset({2}) con confianza: 1.0\n",
      "frozenset({2, 5}) --> frozenset({1}) con confianza: 1.0\n",
      "frozenset({1, 2}) --> frozenset({5}) con confianza: 1.0\n",
      "\n",
      "La confianza de la primera regla es: 1.0\n"
     ]
    }
   ],
   "source": [
    "reglas = generarReglas(L, soporteCk, minC=0.7)\n",
    "\n",
    "print('\\nLa confianza de la primera regla es:',reglas[0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIcl9388vzK4"
   },
   "source": [
    "\n",
    "Es curioso el hecho de que girando la regla $5 \\to 1$ obtenemos otra regla con la confianza requerida y, sin embargo, al hacer lo mismo con la regla $3\\to 2$, la regla resultante no supera el umbral marcado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0dgCcbROvzK4"
   },
   "source": [
    "<hr />\n",
    "\n",
    "<center><h1>Librerias de Python</h1></center>\n",
    "\n",
    "Una librería interesante que incluye el algoritmo Apriori es <b>apyori</b> (hay que descargarlo con `!wget https://raw.githubusercontent.com/ymoch/apyori/master/apyori.py`). Veamos como funciona.\n",
    "\n",
    "Para empezar, cargamos las librerías necesarias y el conjunto de transacciones que usaremos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9680 sha256=6b1ddf0fa816ea3585e82c7ec9aa875cb55d76ded2ca2f5a9ced538c1e58a999\n",
      "  Stored in directory: /Users/mayrita/Library/Caches/pip/wheels/bd/a8/c3/3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "u6yA48fnwOzl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: wget: command not found\n",
      "/bin/bash: wget: command not found\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/ymoch/apyori/master/apyori.py\n",
    "!wget https://raw.githubusercontent.com/flifuehu/viu-unsupervised-learning/master/datasets/apriori/store_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "TnKNbv0pvzK4"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'apyori'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-6ce7a7c56eac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mapyori\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapriori\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmatriz_datos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'store_data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'apyori'"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "from apyori import apriori  \n",
    "\n",
    "matriz_datos = pd.read_csv('store_data.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ib8SsGBvvzK6"
   },
   "source": [
    "\n",
    "El algoritmo necesita que las transacciones se le pasen como una lista de listas, por lo que el primer paso es transformar la matriz de datos anterior en una lista de ese estilo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u6nRExQbvzK6"
   },
   "outputs": [],
   "source": [
    "transacciones = []  \n",
    "for i in np.arange(matriz_datos.shape[0]):  \n",
    "    transacciones.append([str(matriz_datos.values[i,j]) \n",
    "                          for j in np.arange(matriz_datos.shape[1])\n",
    "                          if str(matriz_datos.values[i,j]) != 'nan'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lZot0oWvzK8"
   },
   "source": [
    "\n",
    "Podemos inspeccionar unas pocas transacciones para ver cómo lucen:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "seb1BSIGvzK9"
   },
   "outputs": [],
   "source": [
    "for i in np.arange(8):\n",
    "    print(' + Transacción',i+1,':',', '.join(transacciones[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQtXyeKyvzK-"
   },
   "source": [
    "\n",
    "Con estas transacciones, ya podemos aplicar el algoritmo Apriori dados unos requisitos de soporte y confianza mínimas:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IzVcG3AzvzK-"
   },
   "outputs": [],
   "source": [
    "lReglas = apriori(transacciones, min_support=0.005, min_confidence=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wqX8uzf6vzLA"
   },
   "source": [
    "\n",
    "En este caso, también podríamos fijar la métrica <i>Lift</i>.\n",
    "\n",
    "Podemos observar las reglas resultantes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HklflHc1vzLB"
   },
   "outputs": [],
   "source": [
    "lReglas = list(lReglas) \n",
    "print('Se han encontrado',len(lReglas),'reglas con los requisitos impuestos')\n",
    "print('La primera regla es:\\n',lReglas[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRHHu9_fvzLE"
   },
   "source": [
    "\n",
    "Podemos ver que tenemos muchísima información sobre la regla codificada en las respuestas.\n",
    "\n",
    "Si queremos hacer un recorrido por todas ellas, podemos hacerlo de la siguiente manera:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8xCrtNw3vzLF",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for item in lReglas:\n",
    "\n",
    "    par = [x for x in item[0]]\n",
    "    print(\"Regla: \" + par[0] + \" -> \" + par[1])\n",
    "\n",
    "    print(\" + Soporte:   {0:1.3f}\".format(item[1]))\n",
    "    print(\" + Confianza: {0:1.3f}\".format(item[2][0][2]))\n",
    "    print(\" + Lift:      {0:1.3f}\".format(item[2][0][3]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9yKtSLi8vzLH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "N4.2 - Algoritmo APRIORI.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
