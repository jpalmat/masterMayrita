{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "from skimage.feature import hog\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ PREDICCIÓN ################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar todos los objetos obtenidos durante el entrenamiento\n",
    "# estandarizador\n",
    "with open('objetos/estandarizador.pickle', 'rb') as fr:\n",
    "    std = pickle.load(fr)\n",
    "    \n",
    "# selector\n",
    "with open('objetos/selector.pickle', 'rb') as fr:\n",
    "    sel = pickle.load(fr)\n",
    "\n",
    "# model\n",
    "with open('objetos/clasificador.pickle', 'rb') as fr:\n",
    "    model = pickle.load(fr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos de test\n",
    "images, target  = [], []\n",
    "folder = os.listdir('digits/test/')\n",
    "\n",
    "for i in np.arange(len(folder)):\n",
    "    name = folder[i] # name image\n",
    "    img = cv2.imread('digits/test/' + name, 0)\n",
    "    img[img<255]=0\n",
    "    images.append(img)\n",
    "    \n",
    "    idx = name.find('_')\n",
    "    tgt = int(name[idx+1])\n",
    "    target.append(tgt)\n",
    "\n",
    "images = np.array(images)\n",
    "target = np.array(target)\n",
    "print(np.shape(images))\n",
    "print(np.shape(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Extracción de características de test\n",
    "X_test = []\n",
    "y_test = target\n",
    "for i in np.arange(len(folder)):\n",
    "    features = hog(images[i], orientations=9, pixels_per_cell=(4, 4), cells_per_block=(2, 2), \n",
    "                   transform_sqrt=True, block_norm=\"L1\")\n",
    "    X_test.append(features)\n",
    "    \n",
    "X_test = np.array(X_test)\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Estandarización de características de test\n",
    "X_test = std.transform(X_test)\n",
    "print(np.shape(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Selección de características\n",
    "X_test= sel.transform(X_test)\n",
    "print(np.shape(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Extraer predicciones\n",
    "y_pred = model.predict(X_test)\n",
    "print(np.shape(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Evaluar resultados\n",
    "from tabulate import tabulate\n",
    "from sklearn import metrics\n",
    "\n",
    "headers = ['', 'CLF']\n",
    "P, S, FS, ACC = [['Precision'], ['Sensibilidad'], ['F1-Score'], ['Accuracy']]\n",
    "\n",
    "P.append(np.round(metrics.precision_score(y_test, y_pred, average='macro'),4))\n",
    "S.append(np.round(metrics.recall_score(y_test, y_pred, average='macro'),4))\n",
    "FS.append(np.round(metrics.f1_score(y_test, y_pred, average='macro'), 4))\n",
    "ACC.append(np.round(metrics.accuracy_score(y_test, y_pred), 4))\n",
    "\n",
    "my_data = [tuple(P), tuple(S), tuple(FS), tuple(ACC)]\n",
    "print(tabulate(my_data, headers=headers))\n",
    "\n",
    "# Confusion matrix\n",
    "print('\\nCONFUSION MATRIX')\n",
    "print(metrics.confusion_matrix(y_test, y_pred, normalize=None))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
