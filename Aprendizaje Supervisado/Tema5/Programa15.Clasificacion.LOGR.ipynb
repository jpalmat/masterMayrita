{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, train_test_split, KFold\n",
    "from sklearn import preprocessing\n",
    "from evaluacion_funciones import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 2)\n"
     ]
    }
   ],
   "source": [
    "# Carga de datos.\n",
    "datos = load_iris()\n",
    "X = datos.data[:,2:] # Utilizamos solo 2 atributos.\n",
    "y = datos.target\n",
    "print(np.shape(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas de evaluación.\n",
    "metricas = {\n",
    "  'ACC':    metrics.accuracy_score,\n",
    "  'PREC':   lambda y_true, y_pred:\n",
    "            metrics.precision_score(y_true, y_pred, average='micro'),\n",
    "  'RECALL': lambda y_true, y_pred:\n",
    "            metrics.recall_score(y_true, y_pred, average='micro'),\n",
    "  'F1':     lambda y_true, y_pred:\n",
    "            metrics.f1_score(y_true, y_pred, average='micro')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Partición de datos externa\n",
    "X_training, X_testing, y_training, y_testing = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(np.shape(X_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- TRAINING ---------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Extracción de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Estandarización de los datos de entrenamiento\n",
    "standardizer = preprocessing.StandardScaler()\n",
    "stdr_trained = standardizer.fit(X_training)\n",
    "X_stdr = stdr_trained.transform(X_training)\n",
    "# print(X_stdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Selección de atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Construcción del algoritmo de aprendizaje.\n",
    "algoritmos = {'LOGR': LogisticRegression(penalty='l2', solver='saga', max_iter=1000, random_state=42, multi_class='ovr')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1) Validación cruzada interna y Optimización de los hiperparámetros\n",
    "y_pred = {}\n",
    "for nombre, alg in algoritmos.items():\n",
    "    y_pred[nombre] = cross_val_predict(alg, X_stdr, y_training, cv=KFold(n_splits=10, shuffle=True, random_state=42))\n",
    "    results = evaluacion(y_training, y_pred[nombre], metricas)\n",
    "    print(metrics.confusion_matrix(y_training, y_pred[nombre]))\n",
    "    print(results)\n",
    "    \n",
    "#     results = cross_val_score(alg, X_stdr, y_training, cv = KFold(n_splits=10, shuffle=True, random_state=42))\n",
    "#     print(\"Accuracy:   %0.4f +/- %0.4f\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2) Entrenamiento del modelo definitivo\n",
    "model = algoritmos['LOGR'].fit(X_stdr, y_training)\n",
    "\n",
    "# Visualización de las fronteras de decisión\n",
    "mapa_modelo_clasif_2d(X_stdr, y_training, model, results, nombre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- PREDICTION ---------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Extracción de las características de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Estandarización de las característiacs de test\n",
    "X_test_stdr = stdr_trained.transform(X_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Selección de los atributos de test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Predicción del conjunto de test\n",
    "y_pred_test = model.predict(X_test_stdr)\n",
    "print(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) Evaluación del modelo sobre el conjunto de test\n",
    "results = evaluacion(y_testing, y_pred_test, metricas)\n",
    "print(results)\n",
    "print(metrics.confusion_matrix(y_testing, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploteamos la curva ROC\n",
    "y_proba_test = model.predict_proba(X_test_stdr) # \"predict_proba\" para extraer probabilidades vez de predicciones\n",
    "\n",
    "y_test_bin = preprocessing.label_binarize(y_testing, classes=[0,1,2]) # Usar \"label_binarize\" en el caso de problemas multiclase\n",
    "\n",
    "auc = metrics.roc_auc_score(y_testing, y_proba_test, multi_class='ovr') # Area Under the ROC curve (AUC)\n",
    "\n",
    "fpr, tpr, th = metrics.roc_curve(y_test_bin[:,0], y_proba_test[:,0])\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('AUC = ' + str(np.round(auc,4)))\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
