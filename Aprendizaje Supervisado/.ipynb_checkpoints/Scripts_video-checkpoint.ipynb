{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58743a8b",
   "metadata": {},
   "source": [
    "1. Compresión del problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c5feae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos información del documento Excel\n",
    "import pandas as pd\n",
    "dataFrame = pd.read_csv('../Material/Database.csv', sep=';')\n",
    "print(dataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580e8a73-d35f-4fdb-83fa-88139d304cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer información de interés\n",
    "import numpy as np\n",
    "clases, frec = np.unique(dataFrame.Class, return_counts=True)\n",
    "print(clases, frec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689e1c70-5745-4786-b8b5-9a4754ea9995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar una muestra aleatoria de nuestra base de datos\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "num = random.randint(0,len(dataFrame))\n",
    "print(num)\n",
    "name_img = dataFrame.ID[num]\n",
    "print(name_img)\n",
    "\n",
    "img = cv2.imread('../Material/Images/' + name_img)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73388dc9-7f2f-451f-a319-f5cfab268ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos las máscaras y ploteamos los contornos sobre la imagen original\n",
    "rnf1_mask = cv2.imread('../Material/RNFL_masks/' + name_img, 0)\n",
    "retina_mask = cv2.imread('../Material/Retina_masks/' + name_img, 0)\n",
    "\n",
    "cont_rnfl, _ = cv2.findContours(rnfl_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cont_retina, _ = cv2.findContours(retina_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "image = cv2.drawContours(img.copy(), cont_rnfl, -1 (255, 0, 0), 3)\n",
    "image = cv2.drawContours(image.copy(), cont_retina, -1 (0, 255, 0), 3)\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b973be",
   "metadata": {},
   "source": [
    "2. Partición de datos externa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dcdba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Leer la información del documento Excel original\n",
    "dataFrame = pd.read_csv('../Material/Database.csv', sep=';')\n",
    "print(dataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96c24d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partición externa de los datos\n",
    "from sklearn.model_selection import train_test_split, Kfold\n",
    "\n",
    "# train, test = train_test_split(dataFrame, test_size=0.2, shuffle=True, random_state=42) # hold-out\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "bolsas = kf.split(dataFrame)\n",
    "\n",
    "for k, (train_fold, test_fold) in enumerate(bolsas):\n",
    "    train = dataFrame.iloc[train_fold]\n",
    "    test = dataFrame.iloc[test_fold]\n",
    "\n",
    "lab_train, ocur_train = np.unique(train.Class, return_counts=True)\n",
    "lab_test, ocur_test = np.unique(test.Class, return_counts=True)\n",
    "\n",
    "print(' --- TRAIN --- \\nGlaucoma: ', ocur_train[0], '\\nHealthy: ', ocur_train[1])\n",
    "print(' --- TEST --- \\nGlaucoma: ', ocur_test[0], '\\nHealthy: ', ocur_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130520b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503bc53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aleatorizar los dataframes\n",
    "train = train.sample(frac=1)\n",
    "test = test.sample(frac=1)\n",
    "\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366f028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardado de los modelos\n",
    "import os\n",
    "if not os.path.exists('../partitions'):\n",
    "    os.mkdir('../partitions')\n",
    "train.to_csv('../partitions/train.csv', sep=';')\n",
    "test.to_csv('../partitions/test.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d632637",
   "metadata": {},
   "source": [
    "3. Extracción de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bd30d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_train = pd.read_csv('../partitions/train.csv', sep=';')\n",
    "df_test = pd.read_csv('../partitions/test.csv', sep=';')\n",
    "\n",
    "matriz_datos_train = feature_extraction(df_train)\n",
    "matriz_datos_test = feature_extraction(df_test)\n",
    "\n",
    "# print(np.shape(matriz_datos_test))\n",
    "\n",
    "import os\n",
    "if not os.path.exists('../features'):\n",
    "    os.mkdir('../features')\n",
    "\n",
    "np.save('../features/matriz_datos_train.npy', matriz_datos_train)\n",
    "np.save('../features/matriz_datos_test.npy', matriz_datos_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540942bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(df):\n",
    "    \n",
    "    import cv2\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fingerprint = []\n",
    "    for i in range(0, len(df)):\n",
    "#        print('[INFO] --- Extrayendo información para la muestra ', str(i))\n",
    "        file = df.ID[i]\n",
    "        img = cv2.imread('../Material/Images/' + file)\n",
    "        rnfl_mask = cv2.imread('../Material/RNFL_masks/' + file, 0)\n",
    "        retina_mask = cv2.imread('../Material/Retina_masks/' + file, 0)\n",
    "        \n",
    "    #    # Visualización\n",
    "    #    fig, ax = plt.subplots(1,3)\n",
    "    #    ax[0].imshow(img, cmap='gray'), ax[0].set_title('Imagen')\n",
    "    #    ax[1].imshow(rnfl_mask, cmap='gray'), ax[1].set_title('RNFL')\n",
    "    #    ax[2].imshow(retina_mask, cmap='gray'), ax[1].set_title('Retina')\n",
    "        \n",
    "        # ESTADÍSTICOS UNIDIMENSIONALES en la RNFL\n",
    "        thickness_rnfl = []\n",
    "        for j in range (0, rnfl_mask.shape[1]):\n",
    "            pos = np.where(rnfl_mask[:,j]==255)\n",
    "            thickness_rnfl.append(pos[0][-1]-pos[0][0])\n",
    "        thickness_rnfl = np.array(thickness_rnfl)\n",
    "        print(np.shape(thickness_rnfl))\n",
    "        \n",
    "        # Características basadas en medidas de tendencia central\n",
    "        media = np.mean(thickness_rnfl)\n",
    "        mediana = np.median(thickness_rnfl)\n",
    "        \n",
    "        # Características basadas en medidas de dispersión\n",
    "        desvest = np.std(thickness_rnfl)\n",
    "        \n",
    "        # Características de distribución\n",
    "        from scipy import stats\n",
    "        asimetria = stats.skew(thickness_rnfl)\n",
    "        curtosis = stats.kurtosis(thickness_rnfl)\n",
    "        \n",
    "        # Otras características\n",
    "        minimo = np.min(thickness_rnfl)\n",
    "        maximo = np.max(thickness_rnfl)\n",
    "        \n",
    "        # (fingerprint RNFL)\n",
    "        features_RNFL = [media, mediana, desvest, asimetria, curtosis, minimo, maximo] # estadísticos unidimensionales\n",
    "        \n",
    "        # CARACTERÍSTICAS BIDIMENSIONALES en la estructura de la RETINA\n",
    "        from skimage.measure import regionprops\n",
    "        prop = regionprops(retina_mask)\n",
    "        bb = prop[0].bbox\n",
    "        retina = img[bb[0]:bb[2], bb[1]:bb[3], 0]\n",
    "        \n",
    "    #    plt.imshow(retina, cmap='gray')\n",
    "    #    plt.show()\n",
    "        \n",
    "        # Gray-Level Coocurrence Matrix (GLCM)\n",
    "        from skimage.feature import greycomatrix, greycoprops\n",
    "        GLCM = greycomatrix(retina, distances=[2], angles=[90], levels=256, symmetric=True, normed=True)\n",
    "        contraste = greycoprops(GLCM, 'contrast')[0,0]\n",
    "        disimilitud = greycoprops(GLCM, 'dissimilarity')[0,0]\n",
    "        homogeneidad = greycoprops(GLCM, 'homogeneity')[0,0]\n",
    "        ASM = greycoprops(GLCM, 'ASM')[0,0]\n",
    "        energia = greycoprops(GLCM, 'energy')[0,0]\n",
    "        correlacion = greycoprops(GLCM, 'correlation')[0,0]\n",
    "        \n",
    "        # Local Binary Patterns (LBP)\n",
    "        from skimage.feature import local_binary_pattern\n",
    "        R=1 # radio\n",
    "        P=8*R # vecinos\n",
    "        lbp_image = local_binary_pattern(retina, P, R, method='uniform')\n",
    "        \n",
    "        lbp_image = np.uint8(lbp_image)\n",
    "        \n",
    "        hist_lbp = cv2.calcHist([lbp_image.ravel()], [0], None, [p+2], [0, p+2])\n",
    "        hist_lbp = hist_lbp.astype('float')\n",
    "        hist_lbp /= (hist_lbp.sum() + 1e-7)\n",
    "        hist_lbp = hist_lbp.tolist()\n",
    "        hist_lbp = [item for sublist in hist_lbp for item in sublist]\n",
    "        \n",
    "        # Visualización de la imagen lbp y el histograma\n",
    "    #    plt.imshow(retina, cmap='gray')\n",
    "    #    plt.show()\n",
    "        \n",
    "    #    plt.imshow(lbp_image, cmap='gray')\n",
    "    #    plt.show()\n",
    "        \n",
    "    #    plt.plot(hist_lbp)\n",
    "    #    plt.grid(True)\n",
    "    #    plt.show()\n",
    "        \n",
    "        # Características de textura (fingerprint retina)\n",
    "        features_Retina = [contraste, disimilitud, homogeneidad, ASM, energia, correlacion] + hist_lbp # Características bidimensionales\n",
    "        \n",
    "        # Extraer la información de la clase\n",
    "        if df.Class[i] == 'Healthy':\n",
    "            etiqueta = [0]\n",
    "        else:\n",
    "            etiqueta = [1]\n",
    "        \n",
    "        fingerprint.append(features_RNFL + features_Retina + etiqueta)\n",
    "    #    print(np.shape(fingerprint))\n",
    "    \n",
    "    matriz_datos = np.array(fingerprint)\n",
    "#    print(np.shape(matriz_datos))\n",
    "    \n",
    "    return matriz_datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b00a3d",
   "metadata": {},
   "source": [
    "4. Selección de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819c6a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos de entrenamiento\n",
    "import numpy as np\n",
    "train_matrix = np.load('../features/matriz_datos_train.npy')\n",
    "\n",
    "# Seleccionar las features y target\n",
    "X_train = train_matrix[:,:-1]\n",
    "y_train = train_matrix[:, -1]\n",
    "\n",
    "print(np.shape(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aa6a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarización de los datos de entrenamiento\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "estandarizador = StandardScaler()\n",
    "estandarizador.fit(X_train)\n",
    "mu = estandarizador.mean_\n",
    "sigma = np.sqrt(estandarizador.var_)\n",
    "X_train = estandarizador.transform(X_train)\n",
    "\n",
    "# print(X_train[0])\n",
    "# print(X_train_new[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd426e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECCIÓN DE LOS ATRIBUTOS (CARACTERÍSTICAS)\n",
    "# Estudiar si las variables siguen una distribución normal de media 0 y desviación típica 1 --> N(0,1)\n",
    "from scipy.stats import kstest # Prueba de Kolmogorov-Smirnov\n",
    "\n",
    "alpha = 0.01 # nivel de confianza del 99%\n",
    "h_norm = np.zeros(X_train.shape[1])\n",
    "for i in range(0, X_train.shape[1]):\n",
    "    _, pvalue = kstest(X_train[:, i], 'norm')\n",
    "    \n",
    "    # Contraste de hipótesis\n",
    "    if pvalue<=alpha:\n",
    "        h_norm[i] = 0 # Los datos NO siguen una distribución normal N(0,1)\n",
    "    else:\n",
    "        h_norm[i] = 1 # Los datos SÍ siguen una distribución normal N(0,1)\n",
    "\n",
    "print('0: no normal  ---- 1: sí normal: ', h_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55114a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxplot(data1, data2, ticks):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    bpl = plt.boxplot(data1, positions=np.array(range(np.shape(data1)[1]))*2.0-0.4, sym='', widths=0.5, \\\n",
    "                      boxprops=dict(color='red'),\n",
    "                      capprops=dict(color='red'),\n",
    "                      whiskerprops=dict(color='red'),\n",
    "                      medianprops=dict(color='red'))\n",
    "    \n",
    "    bpl = plt.boxplot(data2, positions=np.array(range(np.shape(data2)[1]))*2.0-0.4, sym='', widths=0.5, \\\n",
    "                      boxprops=dict(color='blue'),\n",
    "                      capprops=dict(color='blue'),\n",
    "                      whiskerprops=dict(color='blue'),\n",
    "                      medianprops=dict(color='blue'))\n",
    "    \n",
    "    plt.plot([], c='#D7191C', label='Glaucoma')\n",
    "    plt.plot([], c='#2C7BB6', label='Healthy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.xticks(range(0, len(ticks)*2, 2), ticks)\n",
    "    plt.xlim(-2, len(ticks)*2)\n",
    "    plt.grid(True)\n",
    "    plt.title('Características')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a8ddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estudiar la capacidad discriminativa de los atributos en función de su distribución\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "\n",
    "glaucoma_data = X_train[y_train==1]\n",
    "healthy_data = X_train[y_train==0]\n",
    "\n",
    "h = np.zeros(X_train.shape[1])\n",
    "h_disc = np.zeros(X_train.shape[1])\n",
    "\n",
    "for i in range(0, X_train.shape[1]):\n",
    "    if h_norm[i] == 0: # no es normal --> comparación de medianas (mannwhitneyu)\n",
    "        _, pvalue = mannwhitneyu(glaucoma_data[:,i], healthy_data[:,i])\n",
    "    else: # sí es normal --> comparación de medias (ttest_ind)\n",
    "        _, pvalue = ttest_ind(glaucoma_data[:,i], healthy_data[:,i])\n",
    "    \n",
    "    # constraste de hipótesis, estudiar el poder discriminatorio de las características\n",
    "    # H0: independencia entre la característica y la clase\n",
    "    if pvalue<=alpha:\n",
    "        h_disc[i] = 1 # Se rechaza la H0 y, por tanto, asumimos la dependencia entre la característica y la clase\n",
    "    else:\n",
    "        h_disc[i] = 0 # No hay evidencia para rechazar la H0 y, por tanto, asumimos que la caract. y la clase son independientes\n",
    "\n",
    "print('0: no discrimina, 1: sí discrimina', h_disc)\n",
    "\n",
    "# Eliminando las variables que no son discriminatorias.\n",
    "id_no_disc = np.where(h_disc==0)\n",
    "X_train_disc = np.delete(X_train, id_no_disc[0], axis=1)\n",
    "mu_disc = np.delete(mu, id_no_disc[0])\n",
    "sigma_disc = np.delete(sigma, id_no_disc[0])\n",
    "\n",
    "print(np.shape(X_train_disc))\n",
    "print(np.shape(mu_disc))\n",
    "print(np.shape(sigma_disc))\n",
    "\n",
    "# Visualización\n",
    "original_ticks = ['media', 'mediana', 'std', 'asim', 'curtosis', 'min', 'max', 'con', 'dis', 'homo', 'ASM', 'E', 'COR',\n",
    "         'LBP1', 'LBP2', 'LBP3', 'LBP4', 'LBP5', 'LBP6', 'LBP7', 'LBP8', 'LBP9', 'LBP10']\n",
    "draw_boxplot(glaucoma_data[:,:10], healthy_data[:,:10], original_ticks[:10])\n",
    "\n",
    "ticks = np.delete(original_ticks, id_no_disc[0])\n",
    "print('Características discriminatorias: ', ticks)\n",
    "print('Características NO discriminatorias: ', np.setdiff1d(original_ticks, ticks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7e571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar un análisis de CORRELACIÓN para ver la dependencia entre pares de variables\n",
    "\n",
    "R = np.corrcoef(X_train_disc.transpose())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(R, cmap='jet')\n",
    "plt.show()\n",
    "\n",
    "th_cor = 0.9\n",
    "\n",
    "idx = abs(R)>th_cor\n",
    "mat_tri_sup = np.triu(idx,1)\n",
    "# print(mat_tri_sup.astype('uint8'))\n",
    "\n",
    "row, col = np.where(mat_tri_sup==True)\n",
    "id_corr = np.unique(col)\n",
    "print(id_corr)\n",
    "\n",
    "print('Características correladas: ', ticks[id_corr])\n",
    "print('Características NO correladas: ', np.setdiff1d(ticks, ticks[id_corr]))\n",
    "\n",
    "# Eliminamos las variables correlacionadas\n",
    "X_final = np.delete(X_train_disc, id_corr, axis=1)\n",
    "mu_final = np.delete(mu_disc, id_corr)\n",
    "sigma_final = np.delete(sigma_disc, id_corr)\n",
    "ticks = np.delete(ticks, id_corr)\n",
    "\n",
    "print(np.shape(X_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c516933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardado de matriz final de características\n",
    "import os\n",
    "if not os.path.exists('../final_features'):\n",
    "    os.mkdir('../final_features')\n",
    "\n",
    "y_train_exp = np.expand_dims(y_train, axis=1)\n",
    "train_matrix = np.concatenate((X_final, y_train_exp), axis=1)\n",
    "np.save('../final_features/train.npy', train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad6fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repetir el proceso para la selección de las características del test\n",
    "\n",
    "test_matrix = np.load('../features/matriz_datos_test.npy')\n",
    "\n",
    "# Seleccionar las características y la clase\n",
    "X_test = test_matrix[:,:-1]\n",
    "y_test = test_matrix[:, -1]\n",
    "\n",
    "# Eliminar las características que no son discriminatorias durante entrenamiento\n",
    "# id_no_disc\n",
    "X_test_disc = np.delete(X_test, id_no_disc[0], axis=1)\n",
    "\n",
    "# Eliminar las características correladas durante entrenamiento\n",
    "# id_corr\n",
    "X_test_final = np.delete(X_test_disc, id_corr, axis=1)\n",
    "\n",
    "# Estandarización de las características del test en base a la mu y la sigma del entrenamiento\n",
    "X_test_final = (X_test_final-mu_final)/sigma_final\n",
    "\n",
    "# Guardado de la matriz de datos de test\n",
    "y_test_exp = np.expand_dims(ytest, axis=1)\n",
    "test_matrix = np.concatenate((X_test_final, y_test_exp), axis=1)\n",
    "\n",
    "np.save('../final_features/test.npy', test_matrix)\n",
    "\n",
    "print(np.shape(Xtest_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4873224",
   "metadata": {},
   "source": [
    "5. Modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347f6c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos de entrenamiento\n",
    "import numpy as np\n",
    "train = np.load('../final_features/train.npy')\n",
    "\n",
    "X_train = train[:,:-1]\n",
    "y_train = train[:, -1]\n",
    "\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c8b299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los modelos de clasificación\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "algoritmos = {'LOGR': LogisticRegression(penalty='l2', solver='saga', max_iter=1000, random_state=42),\n",
    "             'MLP': MLPClassifier(hidden_layer_sizes=[8,4], activation='relu', solver='sgd', batch_size='auto',\n",
    "                                  learning_rate='adaptive', learning_rate_init=0.01, max_iter=1000, random_state=42)}\n",
    "# Cross-validation interno en k=5 bolsas\n",
    "from sklearn.model_selection import cross_val_score, Kfold\n",
    "\n",
    "results={}\n",
    "for nombre, alg in algoritmos.items():\n",
    "    results[nombre] = cross_val_score(alg, X_train, y_train, cv=Kfold(n_splits=5, shuffle=True, random_state=42))\n",
    "    print(nombre + ':  Accuracy:  %0.4f +/- %0.4f'% (results[nombre].mean(), results[nombre].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2c221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el modelo definitivo.\n",
    "algoritmos = {'LOGR': LogisticRegression(penalty='l2', solver='saga', max_iter=1000, random_state=42),\n",
    "             'MLP': MLPClassifier(hidden_layer_sizes=[8,4], activation='relu', solver='sgd', batch_size='auto',\n",
    "                                  learning_rate='adaptive', learning_rate_init=0.01, max_iter=1000, random_state=42)}\n",
    "\n",
    "LOGR_definitivo = LOGR.fit(X_train, y_train)\n",
    "MLP_definitivo = MLP.fit(X_train, y_train)\n",
    "\n",
    "# Atributos se obtienen durante el entrenamiento\n",
    "print('Mínimo error cometido: ', MLP_definitivo.best_loss_)\n",
    "print('Número de iteraciones llevadas a cabo: ', MLP_definitivo.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0a47e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar modelos\n",
    "import os\n",
    "if not os.path.exists('../models'):\n",
    "    os.mkdir('../models')\n",
    "\n",
    "import pickle\n",
    "with open('../models/LOGR.pickle', 'wb') as fw:\n",
    "    pickle.dump(LOGR_definitivo, fw)\n",
    "with open('../models/MLP.pickle', 'wb') as fw:\n",
    "    pickle.dump(MLP_definitivo, fw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d080f3b9",
   "metadata": {},
   "source": [
    "6. Evaluación resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dc5df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos del test\n",
    "import numpy as np\n",
    "test = np.load('../final_features/test.npy')\n",
    "\n",
    "X_test = test[:,:-1]\n",
    "y_test = test[:, -1]\n",
    "\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b58612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los modelos entrenados\n",
    "import pickle\n",
    "with open('../models/LOGR.pickle', 'rb') as fr:\n",
    "    LOGR = pickle.load(fr)\n",
    "with open('../models/MLP.pickle', 'rb') as fr:\n",
    "    MLP = pickle.load(fr)\n",
    "\n",
    "# Extraer las predicciones\n",
    "y_pred_LOGR = LOGR.predict(X_test)\n",
    "y_pred_MLP = MLP.predict(X_test)\n",
    "\n",
    "y_pred = [y_pred_LOGR, y_pred_MLP]\n",
    "\n",
    "# Evaluar diversas métricas de clasificación\n",
    "from sklearn import metrics\n",
    "\n",
    "from tabulate import tabulate\n",
    "headers = ['', 'LOGR', 'MPL']\n",
    "P, S, FS, ACC, AUC = [['Precision'], ['Sensibilidad'], ['F1-Score'], ['Accuracy'], ['AUC']]\n",
    "\n",
    "for i in range(0,2):\n",
    "    P.append(np.round(metrics.precision_score(y_test, y_pred[i]),4))\n",
    "    S.append(np.round(metrics.recall_score(y_test, y_pred[i]),4))\n",
    "    FS.append(np.round(metrics.f1_score(y_test, y_pred[i]),4))\n",
    "    ACC.append(np.round(metrics.accuracy_score(y_test, y_pred[i]),4))\n",
    "    AUC.append(np.round(metrics.roc_auc_score(y_test, y_pred[i]),4))\n",
    "\n",
    "my_data = [tuple(P), tuple(S), tuple(FS), tuple(ACC), tuple(AUC)]\n",
    "print(tabulate(my_data, headers=headers))\n",
    "\n",
    "# Confusion matrix\n",
    "print(metrics.confusion_matrix(y_test, y_pred[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
