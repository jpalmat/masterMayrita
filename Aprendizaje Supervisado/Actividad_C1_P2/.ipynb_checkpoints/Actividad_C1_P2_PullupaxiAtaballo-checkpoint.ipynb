{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convocatoria 1 - Proyecto 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1 (4 puntos)\n",
    "Utilizar el conjunto de datos \"dataset_1.npy\" para resolver el ejercicio. Tener en cuenta que la última columna corresponde a la clase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.a) Imputación de valores ausentes (2 puntos)\n",
    "\n",
    "- En aquellas instancias (filas) que contengan UN ÚNICO VALOR NaN en alguno de sus atributos (columnas), se imputará dicho valor.\n",
    " * Si el atributo corresponde a una variable discreta, se imputará el valor utilizando la moda de dicho atributo. \n",
    " * Si el atributo corresponde a una variable continua, se imputará el valor utilizando la media de dicho atributo. \n",
    "- Aquellas instancias (filas) que contengan MÁS DE UN VALOR NaN en sus atributos, deberán ser eliminadas por completo. \n",
    "\n",
    "Los outputs deberán ser: \n",
    "- Una matriz \"X\" de dimensiones M x N, donde M será el número de instancias y N, el de atributos.\n",
    "- Un vector \"y\" de dimensiones M. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 8)\n"
     ]
    }
   ],
   "source": [
    "# Carga de datos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "datos_train = np.load('dataset_1.npy')\n",
    "\n",
    "# Separación de los atributos e instancias para la matriz X y el vector y\n",
    "X = datos_train[:,:-1]\n",
    "y = datos_train[:,-1]\n",
    "\n",
    "print(np.shape(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(495, 8)\n"
     ]
    }
   ],
   "source": [
    "# Se depura aquellas instancias (filas) que contengan MÁS DE UN VALOR NaN en sus atributos, deberán ser eliminadas por completo.\n",
    "nulo = np.count_nonzero(np.isnan(X), axis=1)\n",
    "X_data = np.delete(X, np.where(nulo > 1), axis=0)\n",
    "\n",
    "print(np.shape(X_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Se valida si existen datos continuos o discretos\n",
    "continuo_cols = pd.DataFrame(X_data).select_dtypes(include=['float64', 'int']).columns.to_list()\n",
    "discreto_cols = pd.DataFrame(X_data).select_dtypes(include=['bool']).columns.to_list()\n",
    "\n",
    "print(continuo_cols)\n",
    "print(discreto_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(495, 8)\n"
     ]
    }
   ],
   "source": [
    "# Si el atributo corresponde a una variable continua, se imputará el valor utilizando la media de dicho atributo.\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean') # Utilizamos la estrategia de la media\n",
    "imputer_entrenado = imp.fit(X_data)\n",
    "X_valor = imputer_entrenado.transform(X_data)\n",
    "print(np.shape(X_valor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          4.          1.         ...  9.04481012  8.2603626\n",
      "   7.37490176]\n",
      " [ 0.          4.          0.         ...  8.56908202 10.9370737\n",
      "  10.30131004]\n",
      " [ 0.          3.          1.         ...  9.68777842 10.69134847\n",
      "  11.45671439]\n",
      " ...\n",
      " [ 0.          2.          0.         ...  2.95882711  1.94458971\n",
      "   8.88390924]\n",
      " [ 0.          3.          2.         ...  2.95542398  1.92895933\n",
      "   9.03304966]\n",
      " [ 0.          4.          0.         ...  2.94928374  2.0478487\n",
      "   8.86096477]]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Los outputs deberán ser:\n",
    "# Una matriz \"X\" de dimensiones M x N, donde M será el número de instancias y N, el de atributos.\n",
    "# Un vector \"y\" de dimensiones M.\n",
    "\n",
    "print(X_valor)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.b) Eliminación de valores outliers extremos (2 puntos)\n",
    "- Aplicar el método de Elliptic Envelope fijando una semilla en 42\n",
    "- Utilizar el diagrama de caja y bigotes para establecer los umbrales de decisión\n",
    "- Plotear el diagrama (box and whiskers) obtenido a partir de las puntuaciones calculadas con el método Elliptic Envelope\n",
    "- Eliminar las instancias que contengan valores outliers extremos\n",
    "\n",
    "Los outputs deberán ser: \n",
    "- Una matriz \"X\" de dimensiones M' x N, donde M' será el nuevo número de instancias y N, el de atributos.\n",
    "- Un vector \"y\" de dimensiones M'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(495,)\n"
     ]
    }
   ],
   "source": [
    "# Limpieza de datos: detección de outliers.\n",
    "# Aplicar el método de Elliptic Envelope fijando una semilla en 42\n",
    "outlier_method = EllipticEnvelope(support_fraction=1, random_state = 42).fit(X_valor)\n",
    "\n",
    "# Obtenemos unos valores de puntuación a nivel de instancia para determinar después las que corresponden con valores atípicos\n",
    "scores_pred = outlier_method.decision_function(X_valor)\n",
    "print(np.shape(scores_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limite inferior:  -6.476930623286433\n",
      "limite superior:  19.45329215525228\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Utilizar el diagrama de caja y bigotes para establecer los umbrales de decisión de los cuales vamos a determinar qué valores son outliers\n",
    "\n",
    "Q1 = stats.scoreatpercentile(scores_pred, 25)\n",
    "Q3 = stats.scoreatpercentile(scores_pred, 75)\n",
    "RIC = Q3 - Q1\n",
    "li = Q1 - 1.5*RIC #xmin\n",
    "ls = Q3 + 1.5*RIC #xmax\n",
    "\n",
    "print('limite inferior: ', li)\n",
    "print('limite superior: ', ls)\n",
    "\n",
    "plt.boxplot(scores_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posición de outliers en el extremo inferior:  [ 67 449 470]\n",
      "Posición de outliers en el extremo superior:  []\n"
     ]
    }
   ],
   "source": [
    "# Estimación de outliers. Encontramos la posición de los outliers dentro de nuestros conjunto de datos\n",
    "pos_i = np.where(scores_pred<li)\n",
    "pos_s = np.where(scores_pred>ls)\n",
    "\n",
    "print('Posición de outliers en el extremo inferior: ', pos_i[0])\n",
    "print('Posición de outliers en el extremo superior: ', pos_s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_outliers = np.zeros(np.shape(scores_pred))\n",
    "mask_outliers[pos_i] = 1\n",
    "mask_outliers[pos_s] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.] [492   3]\n",
      "Número de instancias normales:  492\n",
      "Número de instancias atípicas:  3\n"
     ]
    }
   ],
   "source": [
    "# Contamos el número de datos reales y de outliers que hemos detectado\n",
    "valores, ocurrencias = np.unique(mask_outliers, return_counts=True)\n",
    "print(valores, ocurrencias)\n",
    "print('Número de instancias normales: ', ocurrencias[0])\n",
    "print('Número de instancias atípicas: ', ocurrencias[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(492, 8)\n",
      "[[ 0.          4.          1.         ...  9.04481012  8.2603626\n",
      "   7.37490176]\n",
      " [ 0.          4.          0.         ...  8.56908202 10.9370737\n",
      "  10.30131004]\n",
      " [ 0.          3.          1.         ...  9.68777842 10.69134847\n",
      "  11.45671439]\n",
      " ...\n",
      " [ 0.          2.          0.         ...  2.95882711  1.94458971\n",
      "   8.88390924]\n",
      " [ 0.          3.          2.         ...  2.95542398  1.92895933\n",
      "   9.03304966]\n",
      " [ 0.          4.          0.         ...  2.94928374  2.0478487\n",
      "   8.86096477]]\n"
     ]
    }
   ],
   "source": [
    "# Eliminar las instancias que contengan valores outliers extremos\n",
    "\n",
    "X_final = np.delete(X_valor, np.where(mask_outliers == 1), axis=0)\n",
    "\n",
    "# Dataset sin outliers\n",
    "print(np.shape(X_final))\n",
    "print(X_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2 (6 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear un programa, con comentarios que aclaren el código, donde se computen las métricas MAE, MSE, RMSE, MAPE y R2 aplicando los regresores OLS y KNN en DOS datasets de regresión (a elegir). Nota: Al menos uno de los datasets deberá ser externo a la librería de scikit-learn.\n",
    "\n",
    "Se debe llevar a cabo:\n",
    "- Exploración de los datos y descripción del dataset\n",
    "- Tratamiento de outliers y valores perdidos (si los hay)\n",
    "- Partición externa de datos\n",
    "- Estandarización de los datos\n",
    "- Selección de atributos mediante métodos supervisados (solo uno)\n",
    "- Validación cruzada interna para optimizar los hiperparámetros de los algoritmos (si procede)\n",
    "- Modelado\n",
    "- Predicción y evaluación sobre el conjunto de test (resultados cuantitativos y cualitativos)\n",
    "- Breve discusión comparando los resultados obtenidos con cada método."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from math import sqrt\n",
    "from pprint import pprint\n",
    "from sklearn import datasets, linear_model, metrics\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import cross_validate, KFold, cross_val_predict, train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.feature_selection import SelectPercentile, f_regression\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de X:  (442, 10)\n"
     ]
    }
   ],
   "source": [
    "# Exploración de los datos y descripción del dataset: El dataset es de diabetes de la librería sklearn\n",
    "# Al cargar devuelve el conjunto de datos de diabetes (clasificación).\n",
    "\n",
    "datos = datasets.load_diabetes()\n",
    "X = datos.data\n",
    "y = datos.target\n",
    "print('Dimensiones de X: ', np.shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limite inferior:  50.708155017995836\n",
      "limite superior:  114.9145448935088\n",
      "Número de instancias normales:  371\n",
      "Número de instancias atípicas:  71\n",
      "(371, 10)\n"
     ]
    }
   ],
   "source": [
    "# Se trata los outliers\n",
    "outlier = EllipticEnvelope(random_state = 42).fit(X)\n",
    "\n",
    "score = outlier.decision_function(X)\n",
    "Q1 = stats.scoreatpercentile(score, 25)\n",
    "Q3 = stats.scoreatpercentile(score, 75)\n",
    "RIC = Q3 - Q1\n",
    "li = Q1 - 1.5*RIC #xmin\n",
    "ls = Q3 + 1.5*RIC #xmax\n",
    "\n",
    "print('limite inferior: ', li)\n",
    "print('limite superior: ', ls)\n",
    "\n",
    "pos_i = np.where(score<li)\n",
    "pos_s = np.where(score>ls)\n",
    "\n",
    "mask_outliers = np.zeros(np.shape(score))\n",
    "mask_outliers[pos_i] = 1\n",
    "mask_outliers[pos_s] = 1\n",
    "\n",
    "valores, ocurrencias = np.unique(mask_outliers, return_counts=True)\n",
    "print('Número de instancias normales: ', ocurrencias[0])\n",
    "print('Número de instancias atípicas: ', ocurrencias[1])\n",
    "\n",
    "X_data= np.delete(X, np.where(mask_outliers == 1), axis=0)\n",
    "y_data= np.delete(y, np.where(mask_outliers == 1), axis=0)\n",
    "\n",
    "# Dataset sin outliers\n",
    "print(np.shape(X_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(296, 10)\n",
      "(75, 10)\n"
     ]
    }
   ],
   "source": [
    "# Partición externa de datos\n",
    "X_training, X_testing, y_training, y_testing = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n",
    "print(np.shape(X_training))\n",
    "print(np.shape(X_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarización de los datos\n",
    "standardizer = preprocessing.StandardScaler()\n",
    "X_stdr = standardizer.fit_transform(X_training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(296, 9)\n"
     ]
    }
   ],
   "source": [
    "# Selección de atributos mediante métodos supervisados (solo uno)\n",
    "# Se escoge F-Test.\n",
    "sel = SelectPercentile(score_func = f_regression, percentile=90)\n",
    "X_training = sel.fit_transform(X_stdr, y_training)\n",
    "print(np.shape(X_training))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Métricas de evaluación.\n",
    "metricas = {\n",
    "  'MAE': 'neg_mean_absolute_error',\n",
    "  'MSE': 'neg_mean_squared_error',\n",
    "  'RMSE': 'neg_root_mean_squared_error',\n",
    "  'MAPE': 'neg_mean_absolute_percentage_error',\n",
    "  'R2':   'r2'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'OLS': {'fit_time': array([0.00088882, 0.00145912, 0.00127292, 0.00197983, 0.00090599,\n",
      "       0.00128603, 0.00088501, 0.00063491, 0.00083303, 0.00083518]), 'score_time': array([0.00159407, 0.00175714, 0.00190401, 0.00129199, 0.00142717,\n",
      "       0.00206304, 0.00119495, 0.00106907, 0.00134397, 0.00126481]), 'test_MAE': array([-44.91191103, -46.98493084, -37.1533457 , -40.91677693,\n",
      "       -48.60310159, -47.47985649, -52.01568651, -41.70569986,\n",
      "       -50.03017475, -38.91129089]), 'test_MSE': array([-3015.61453002, -3450.49594571, -2012.6954239 , -2292.87802503,\n",
      "       -3707.2534185 , -3586.14611488, -3648.10426643, -2662.31957402,\n",
      "       -3910.06174444, -2611.6500293 ]), 'test_RMSE': array([-54.91461126, -58.74092224, -44.86307417, -47.88400594,\n",
      "       -60.88721884, -59.88443967, -60.39953863, -51.59767024,\n",
      "       -62.53048652, -51.10430539]), 'test_MAPE': array([-0.51055573, -0.32853369, -0.36817141, -0.34665855, -0.53359939,\n",
      "       -0.43510722, -0.45253336, -0.48031471, -0.49014099, -0.28980088]), 'test_R2': array([0.39328928, 0.42995234, 0.42990382, 0.48873654, 0.30009109,\n",
      "       0.28555805, 0.20216242, 0.5821263 , 0.46293168, 0.4920783 ])}, 'KNN': {'fit_time': array([0.0007329 , 0.00055313, 0.00054502, 0.00050712, 0.00053906,\n",
      "       0.00062299, 0.00063396, 0.00053191, 0.00060797, 0.00067687]), 'score_time': array([0.00218701, 0.00189614, 0.00163198, 0.00168395, 0.0017612 ,\n",
      "       0.00168204, 0.00164986, 0.00166416, 0.00226402, 0.00238919]), 'test_MAE': array([-46.64      , -45.42333333, -37.66666667, -46.74666667,\n",
      "       -46.71      , -47.53333333, -55.67586207, -46.61034483,\n",
      "       -55.84137931, -40.64137931]), 'test_MSE': array([-2777.256     , -3338.50366667, -2385.94866667, -3183.32266667,\n",
      "       -3858.05833333, -4001.17533333, -4660.77172414, -3070.13068966,\n",
      "       -4596.12206897, -2452.45448276]), 'test_RMSE': array([-52.69967742, -57.77978597, -48.84617351, -56.42094174,\n",
      "       -62.11327019, -63.25484435, -68.26984491, -55.40876004,\n",
      "       -67.79470532, -49.5222625 ]), 'test_MAPE': array([-0.53616642, -0.28661282, -0.34458449, -0.41952316, -0.4765231 ,\n",
      "       -0.40120932, -0.49161857, -0.52074762, -0.54884193, -0.32311016]), 'test_R2': array([ 0.44124457,  0.4484543 ,  0.3241798 ,  0.29018615,  0.27161996,\n",
      "        0.20287478, -0.01930717,  0.51811687,  0.36869755,  0.52303914])}}\n"
     ]
    }
   ],
   "source": [
    "# # Validación cruzada interna para optimizar los hiperparámetros de los algoritmos (si procede)\n",
    "k = 10\n",
    "algoritmos = {'OLS': linear_model.LinearRegression(),\n",
    "              'KNN': KNeighborsRegressor(n_neighbors = k, weights='uniform', metric='euclidean')}\n",
    "\n",
    "results={}\n",
    "for nombre, alg in algoritmos.items():\n",
    "    results[nombre] = cross_validate(alg, X_training, y_training, cv = KFold(n_splits=10, shuffle=True, random_state=42), scoring=metricas)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelado\n",
    "OLS_definitivo = algoritmos['OLS'].fit(X_training, y_training)\n",
    "KNN_definitivo = algoritmos['KNN'].fit(X_training, y_training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            OLS        KNN\n",
      "----  ---------  ---------\n",
      "MAE     36.6757    40.372\n",
      "MSE   2264.48    2511.28\n",
      "RMSE    47.5866    50.1126\n",
      "MAPE     0.3823     0.4111\n",
      "R2       0.5381     0.4877\n"
     ]
    }
   ],
   "source": [
    "# Estandarización de las característiacs de test\n",
    "X_test = standardizer.transform(X_testing)\n",
    "\n",
    "# Selección de las características de test\n",
    "X_test = sel.transform(X_test)\n",
    "\n",
    "# Predicción del conjunto de test\n",
    "y_pred_test_ols = OLS_definitivo.predict(X_test)\n",
    "y_pred_test_knn = KNN_definitivo.predict(X_test)\n",
    "\n",
    "y_pred = [y_pred_test_ols, y_pred_test_knn]\n",
    "\n",
    "# Evaluar diversas métricas de clasificación\n",
    "from sklearn import metrics\n",
    "\n",
    "from tabulate import tabulate\n",
    "headers = ['', 'OLS', 'KNN']\n",
    "MAE, MSE, RMSE, MAPE, R2 = [['MAE'], ['MSE'], ['RMSE'], ['MAPE'], ['R2']]\n",
    "\n",
    "for i in range(0,2):\n",
    "    MAE.append(np.round(metrics.mean_absolute_error(y_testing, y_pred[i]),4))\n",
    "    MSE.append(np.round(metrics.mean_squared_error(y_testing, y_pred[i], squared=True),4))\n",
    "    RMSE.append(np.round(metrics.mean_squared_error(y_testing, y_pred[i], squared=False),4))\n",
    "    MAPE.append(np.round(metrics.mean_absolute_percentage_error(y_testing, y_pred[i]),4))\n",
    "    R2.append(np.round(metrics.r2_score(y_testing, y_pred[i]),4))\n",
    "\n",
    "my_data = [tuple(MAE), tuple(MSE), tuple(RMSE), tuple(MAPE), tuple(R2)]\n",
    "print(tabulate(my_data, headers=headers))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Breve discusión comparando los resultados obtenidos con cada método\n",
    "\n",
    "Los valores en ambos métodos son parecidos, al igual que cuando se aplica la comparación con el algoritmo de regresión lineal, \n",
    "en el método OLS el MAPE que es el porcentaje de error fue menor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Dataset - Regresion OLS y KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1143, 11)\n",
      "(1143,)\n",
      "[3 4 5 6 7 8] [  6  33 483 462 143  16]\n"
     ]
    }
   ],
   "source": [
    "# Exploración de los datos y descripción del dataset: El dataset WineQT es de Kaggle\n",
    "# Al cargar devuelve el conjunto de datos sobre la calidad del vino.\n",
    "dataFrame = pd.read_csv('WineQT.csv', sep=',')\n",
    "dataFrame.drop(['Id'], axis = 'columns', inplace=True)\n",
    "\n",
    "X = dataFrame.iloc[:, :-1].values\n",
    "y = dataFrame.iloc[:, -1].values\n",
    "\n",
    "print(np.shape(X))\n",
    "print(np.shape(y))\n",
    "\n",
    "#Valores de interés\n",
    "valores, ocurrencias = np.unique(y, return_counts=True)\n",
    "print(valores, ocurrencias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limite inferior:  20.888560921400273\n",
      "limite superior:  74.31006806467427\n",
      "Número de instancias normales:  979\n",
      "Número de instancias atípicas:  164\n",
      "(979, 11)\n"
     ]
    }
   ],
   "source": [
    "# Se trata los outliers\n",
    "outlier = EllipticEnvelope(random_state = 42).fit(X)\n",
    "\n",
    "score = outlier.decision_function(X)\n",
    "Q1 = stats.scoreatpercentile(score, 25)\n",
    "Q3 = stats.scoreatpercentile(score, 75)\n",
    "RIC = Q3 - Q1\n",
    "li = Q1 - 1.5*RIC #xmin\n",
    "ls = Q3 + 1.5*RIC #xmax\n",
    "\n",
    "print('limite inferior: ', li)\n",
    "print('limite superior: ', ls)\n",
    "\n",
    "pos_i = np.where(score<li)\n",
    "pos_s = np.where(score>ls)\n",
    "\n",
    "mask_outliers = np.zeros(np.shape(score))\n",
    "mask_outliers[pos_i] = 1\n",
    "mask_outliers[pos_s] = 1\n",
    "\n",
    "valores, ocurrencias = np.unique(mask_outliers, return_counts=True)\n",
    "print('Número de instancias normales: ', ocurrencias[0])\n",
    "print('Número de instancias atípicas: ', ocurrencias[1])\n",
    "\n",
    "X_data= np.delete(X, np.where(mask_outliers == 1), axis=0)\n",
    "y_data= np.delete(y, np.where(mask_outliers == 1), axis=0)\n",
    "\n",
    "# Dataset sin outliers\n",
    "print(np.shape(X_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(783, 11)\n",
      "(196, 11)\n"
     ]
    }
   ],
   "source": [
    "# Partición externa de datos\n",
    "X_training, X_testing, y_training, y_testing = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n",
    "print(np.shape(X_training))\n",
    "print(np.shape(X_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarización de los datos\n",
    "standardizer = preprocessing.StandardScaler()\n",
    "X_stdr = standardizer.fit_transform(X_training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(783, 9)\n"
     ]
    }
   ],
   "source": [
    "# Selección de atributos mediante métodos supervisados (solo uno)\n",
    "# Se escoge F-Test.\n",
    "sel = SelectPercentile(score_func = f_regression, percentile=90)\n",
    "X_training = sel.fit_transform(X_stdr, y_training)\n",
    "print(np.shape(X_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas de evaluación.\n",
    "metricas = {\n",
    "  'MAE': 'neg_mean_absolute_error',\n",
    "  'MSE': 'neg_mean_squared_error',\n",
    "  'RMSE': 'neg_root_mean_squared_error',\n",
    "  'MAPE': 'neg_mean_absolute_percentage_error',\n",
    "  'R2':   'r2'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'OLS': {'fit_time': array([0.00713205, 0.00123715, 0.00087881, 0.00071311, 0.00107217,\n",
      "       0.00081515, 0.00065517, 0.00065899, 0.00068617, 0.00076485]), 'score_time': array([0.00318503, 0.00147367, 0.00103903, 0.00152969, 0.00142097,\n",
      "       0.00099492, 0.00096583, 0.00098014, 0.00098395, 0.00107408]), 'test_MAE': array([-0.43902159, -0.4612995 , -0.49301815, -0.50349037, -0.40510843,\n",
      "       -0.4508255 , -0.43550515, -0.60339278, -0.46944847, -0.43191123]), 'test_MSE': array([-0.27950597, -0.34791857, -0.43558259, -0.41304493, -0.30493349,\n",
      "       -0.33091699, -0.32245475, -0.60491332, -0.36266251, -0.31127344]), 'test_RMSE': array([-0.52868324, -0.58984623, -0.65998681, -0.64268572, -0.55220783,\n",
      "       -0.57525385, -0.567851  , -0.77776174, -0.60221467, -0.55791885]), 'test_MAPE': array([-0.07926111, -0.08211836, -0.09259135, -0.08741726, -0.07667051,\n",
      "       -0.07700637, -0.07523085, -0.11820519, -0.08400756, -0.07953935]), 'test_R2': array([0.5075108 , 0.346763  , 0.33533718, 0.3052349 , 0.39470952,\n",
      "       0.5056963 , 0.3807403 , 0.28745544, 0.40639259, 0.40596373])}, 'KNN': {'fit_time': array([0.0007062 , 0.00067496, 0.00061798, 0.00065303, 0.00067306,\n",
      "       0.00057006, 0.00060701, 0.00059795, 0.00055385, 0.00049424]), 'score_time': array([0.002877  , 0.00232601, 0.00232196, 0.00263023, 0.00223804,\n",
      "       0.00219798, 0.00665689, 0.00211215, 0.00191808, 0.00179791]), 'test_MAE': array([-0.44177215, -0.45189873, -0.51139241, -0.46794872, -0.44615385,\n",
      "       -0.46794872, -0.37948718, -0.6525641 , -0.47564103, -0.49102564]), 'test_MSE': array([-0.30037975, -0.37379747, -0.42025316, -0.36858974, -0.3674359 ,\n",
      "       -0.3475641 , -0.28128205, -0.67910256, -0.41089744, -0.35858974]), 'test_RMSE': array([-0.54806911, -0.61138978, -0.64826936, -0.60711592, -0.60616491,\n",
      "       -0.58954567, -0.5303603 , -0.8240768 , -0.64101282, -0.59882363]), 'test_MAPE': array([-0.08188668, -0.08253767, -0.09561031, -0.08187424, -0.08434676,\n",
      "       -0.08125458, -0.06559829, -0.12775488, -0.08429792, -0.09015873]), 'test_R2': array([0.47073123, 0.29817389, 0.35872861, 0.38001106, 0.27064274,\n",
      "       0.48082986, 0.45981061, 0.20006583, 0.32744149, 0.31566499])}}\n"
     ]
    }
   ],
   "source": [
    "# # Validación cruzada interna para optimizar los hiperparámetros de los algoritmos (si procede)\n",
    "k = 10\n",
    "algoritmos = {'OLS': linear_model.LinearRegression(),\n",
    "              'KNN': KNeighborsRegressor(n_neighbors = k, weights='uniform', metric='euclidean')}\n",
    "\n",
    "results={}\n",
    "for nombre, alg in algoritmos.items():\n",
    "    results[nombre] = cross_validate(alg, X_training, y_training, cv = KFold(n_splits=10, shuffle=True, random_state=42), scoring=metricas)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelado\n",
    "OLS_definitivo = algoritmos['OLS'].fit(X_training, y_training)\n",
    "KNN_definitivo = algoritmos['KNN'].fit(X_training, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         OLS     KNN\n",
      "----  ------  ------\n",
      "MAE   0.4737  0.5184\n",
      "MSE   0.3784  0.4318\n",
      "RMSE  0.6151  0.6571\n",
      "MAPE  0.0815  0.0904\n",
      "R2    0.4114  0.3283\n"
     ]
    }
   ],
   "source": [
    "# Estandarización de las característiacs de test\n",
    "X_test = standardizer.transform(X_testing)\n",
    "\n",
    "# Selección de las características de test\n",
    "X_test = sel.transform(X_test)\n",
    "\n",
    "# Predicción del conjunto de test\n",
    "y_pred_test_ols = OLS_definitivo.predict(X_test)\n",
    "y_pred_test_knn = KNN_definitivo.predict(X_test)\n",
    "\n",
    "y_pred = [y_pred_test_ols, y_pred_test_knn]\n",
    "\n",
    "# Evaluar diversas métricas de clasificación\n",
    "from sklearn import metrics\n",
    "\n",
    "from tabulate import tabulate\n",
    "headers = ['', 'OLS', 'KNN']\n",
    "MAE, MSE, RMSE, MAPE, R2 = [['MAE'], ['MSE'], ['RMSE'], ['MAPE'], ['R2']]\n",
    "\n",
    "for i in range(0,2):\n",
    "    MAE.append(np.round(metrics.mean_absolute_error(y_testing, y_pred[i]),4))\n",
    "    MSE.append(np.round(metrics.mean_squared_error(y_testing, y_pred[i], squared=True),4))\n",
    "    RMSE.append(np.round(metrics.mean_squared_error(y_testing, y_pred[i], squared=False),4))\n",
    "    MAPE.append(np.round(metrics.mean_absolute_percentage_error(y_testing, y_pred[i]),4))\n",
    "    R2.append(np.round(metrics.r2_score(y_testing, y_pred[i]),4))\n",
    "\n",
    "my_data = [tuple(MAE), tuple(MSE), tuple(RMSE), tuple(MAPE), tuple(R2)]\n",
    "print(tabulate(my_data, headers=headers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Breve discusión comparando los resultados obtenidos con cada método\n",
    "\n",
    "Los valores en ambos métodos son parecidos, cuando se aplica la comparación con el algoritmo de regresión lineal, \n",
    "en el método OLS el MAPE que es el porcentaje de error fue menor y KNN es mayor pero con un pequeña diferencia."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
